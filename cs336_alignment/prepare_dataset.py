import pandas as pd
from pathlib import Path

# ç»å¯¹åŸºå‡†è·¯å¾„é”å®šï¼šç¡®ä¿ç”Ÿæˆåœ¨ cs336_alignment/data/MATH/ ä¸‹
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"

def prepare_math_dataset_final_reliable():
    output_dir = DATA_DIR / "MATH"
    output_path = output_dir / "validation.jsonl"
    output_dir.mkdir(parents=True, exist_ok=True)

    if output_path.exists():
        print(f"âœ… æ•°æ®é›†å·²å­˜åœ¨: {output_path}")
        return

    subjects = ["algebra", "counting_and_probability", "geometry", 
                "intermediate_algebra", "number_theory", "prealgebra", "precalculus"]
    
    # ç»•è¿‡æ‰€æœ‰åº“æ¢æµ‹é€»è¾‘ï¼Œç›´æ¥ç›´è¿è·å– Parquet æ–‡ä»¶
    base_url = "https://huggingface.co/datasets/EleutherAI/hendrycks_math/resolve/main"
    
    all_dfs = []
    print(f"ğŸš€ æ­£åœ¨æ„å»ºéªŒè¯é›† (ç»å¯¹è·¯å¾„æ¨¡å¼)...")

    try:
        for sub in subjects:
            # æ˜¾å¼è·¯å¾„åŠ è½½ï¼Œç»å¯¹ä¸è§¦å‘ ** åŒ¹é…é€»è¾‘
            url = f"{base_url}/{sub}/test-00000-of-00001.parquet"
            df = pd.read_parquet(url)
            all_dfs.append(df)

        final_df = pd.concat(all_dfs, ignore_index=True)
        # å¯¼å‡ºä¸ºä½œä¸šè¦æ±‚çš„ JSONL æ ¼å¼
        final_df.to_json(output_path, orient='records', lines=True, force_ascii=False)
        
        print(f"âœ¨ è½¬æ¢æˆåŠŸï¼æ€»æ ·æœ¬æ•°: {len(final_df)} (é¢„æœŸ ~5000)")
        print(f"ğŸ“„ æ–‡ä»¶å­˜æ”¾åœ¨: {output_path}")

    except Exception as e:
        print(f"âŒ æµç¨‹å¤±è´¥: {e}")

if __name__ == "__main__":
    prepare_math_dataset_final_reliable()